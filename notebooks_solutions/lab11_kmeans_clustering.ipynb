{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('..', 'data', 'tugas_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature names into groups\n",
    "non_metric_features = df.columns[df.columns.str.startswith('x')]\n",
    "pc_features = df.columns[df.columns.str.startswith('PC')]\n",
    "metric_features = df.columns[~df.columns.str.startswith('x') & ~df.columns.str.startswith('PC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "What is K-Means clustering? How does it work?\n",
    "\n",
    "### How is it computed?\n",
    "![](../figures/kmeans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics:\n",
    "- *Number of clusters* need to be set apriori\n",
    "- One of the *fastest* clustering algorithms\n",
    "- The results *depend on the initialization* (stochastic)\n",
    "- Prone to *local optima*\n",
    "- Favors *convex* (round shape) and *isotropic* (same shape) clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some videos showing how K-Means works:**\n",
    "\n",
    "(You might want to mute the videos before playing)\n",
    "\n",
    "How K-Means works: https://www.youtube.com/watch?v=5I3Ei69I40s\n",
    "\n",
    "Effects of different initializations: https://www.youtube.com/watch?v=9nKfViAfajY\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply K-Means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmclust = KMeans(n_clusters=8, init='random', n_init=10, random_state=1)\n",
    "# the fit method\n",
    "kmclust.fit(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict method\n",
    "kmclust.predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the transform method\n",
    "pd.DataFrame(kmclust.transform(df[metric_features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we improve the initialization step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better initialization method and provide more n_init\n",
    "kmclust = KMeans(n_clusters=8, init='k-means++', n_init=15, random_state=1)\n",
    "kmclust.fit(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmclust.predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*init='k-means++'* initializes the centroids to be (generally) distant from each other, leading to probably better results than random initialization. *n_init=K* allows to initialize KMeans K times and pick the best clustering in terms of Inertia. This can been shown in the link below.\n",
    "\n",
    "**Empirical evaluation of the impact of k-means initialization:**\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_stability_low_dim_dense.html#sphx-glr-auto-examples-cluster-plot-kmeans-stability-low-dim-dense-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the number of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_clusters = range(1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n_clus in range_clusters:  # iterate over desired ncluster range\n",
    "    kmclust = KMeans(n_clusters=n_clus, init='k-means++', n_init=15, random_state=1)\n",
    "    kmclust.fit(df[metric_features])\n",
    "    inertia.append(kmclust.inertia_)  # save the inertia of the given cluster solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inertia (within-cluster sum-of-squares distance) Formula:**\n",
    "$$\\sum_{j=0}^{C}\\sum_{i=0}^{n_j}(||x_i - \\mu_j||^2)$$\n",
    ", where:\n",
    "\n",
    "$C$: Set of identified clusters.\n",
    "\n",
    "$n_j$: Set of observations belonging to cluster $j$.\n",
    "\n",
    "$x_i$: Observation $i$.\n",
    "\n",
    "$\\mu_j$: Centroid of cluster $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The inertia plot\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range_clusters, inertia)\n",
    "plt.ylabel(\"Inertia: SSw\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Inertia plot over clusters\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Silhouette Coefficient formula for a single sample:**\n",
    "$$s = \\frac{b - a}{max(a, b)}$$\n",
    ", where:\n",
    "- $a$: The mean distance between a sample and all other points in the same cluster.\n",
    "- $b$: The mean distance between a sample and all other points in the next nearest cluster\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "If $b > a$, then what?\n",
    "\n",
    "Then the sample is closer to the points in the cluster it is assigned to (compared to the points in the next nearest cluster)\n",
    "\n",
    "$s$ is positive\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "If $b = a$, then what?\n",
    "\n",
    "*Then the sample is equally distant to the points in the cluster it is assigned to as well as the points in the next closest cluster*\n",
    "\n",
    "$s$ is 0\n",
    "\n",
    "---\n",
    "\n",
    "If $b < a$, then what?\n",
    "\n",
    "*Then the sample is closer to the points in the next closest cluster (compared to the points in the same cluster).*\n",
    "\n",
    "$s$ is negative\n",
    "\n",
    "---\n",
    "\n",
    "**If the average value of $s$ is high, then what?**\n",
    "\n",
    "\n",
    "\"Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.\"\n",
    "\n",
    "- https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n",
    "\n",
    "# Storing average silhouette metric\n",
    "avg_silhouette = []\n",
    "for nclus in range_clusters:\n",
    "    # Skip nclus == 1\n",
    "    if nclus == 1:\n",
    "        continue\n",
    "    \n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(13, 7))\n",
    "\n",
    "    # Initialize the KMeans object with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    kmclust = KMeans(n_clusters=nclus, init='k-means++', n_init=15, random_state=1)\n",
    "    cluster_labels = kmclust.fit_predict(df[metric_features])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed clusters\n",
    "    silhouette_avg = silhouette_score(df[metric_features], cluster_labels)\n",
    "    avg_silhouette.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {nclus}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(df[metric_features], cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(nclus):\n",
    "        # Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        \n",
    "        # Get y_upper to demarcate silhouette y range size\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        \n",
    "        # Filling the silhouette\n",
    "        color = cm.nipy_spectral(float(i) / nclus)\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    plt.title(\"The silhouette plot for the various clusters.\")\n",
    "    plt.xlabel(\"The silhouette coefficient values\")\n",
    "    plt.ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    plt.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # The silhouette coefficient can range from -1, 1\n",
    "    xmin, xmax = np.round(sample_silhouette_values.min() -0.1, 2), np.round(sample_silhouette_values.max() + 0.1, 2)\n",
    "    plt.xlim([xmin, xmax])\n",
    "    \n",
    "    # The (nclus+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    plt.ylim([0, len(df[metric_features]) + (nclus + 1) * 10])\n",
    "\n",
    "    plt.yticks([])  # Clear the yaxis labels / ticks\n",
    "    plt.xticks(np.arange(xmin, xmax, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The average silhouette plot\n",
    "# The inertia plot\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range_clusters[1:], ## Plot X-axis; Why range_clusters[1:] ? Remember we skipped k=1 in the cell above\n",
    "         avg_silhouette)     ## Plot Y-axis\n",
    "\n",
    "plt.ylabel(\"Average silhouette\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Average silhouette plot over clusters\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final KMeans clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cluster solution\n",
    "number_clusters = 3\n",
    "kmclust = KMeans(n_clusters=number_clusters, init='k-means++', n_init=15, random_state=1)\n",
    "km_labels = kmclust.fit_predict(df[metric_features])\n",
    "km_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "df_concat = pd.concat((df, pd.Series(km_labels, name='labels', index=df.index)), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we combine the 2 algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "**Apply Hierarchical Clustering and K-means on the Principal Components.**\n",
    "\n",
    "Choose the appropriate parameters and number of clusters for each algorithm and interpret each cluster based on the Principal Components interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
