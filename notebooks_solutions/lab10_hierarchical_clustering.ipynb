{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('..', 'data', 'tugas_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature names into groups\n",
    "non_metric_features = df.columns[df.columns.str.startswith('x')]\n",
    "pc_features = df.columns[df.columns.str.startswith('PC')]\n",
    "metric_features = df.columns[~df.columns.str.startswith('x') & ~df.columns.str.startswith('PC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "What is hierarchical clustering? How does it work? How does it relate to the distance matrix we discussed at the beggining of the course? ;)\n",
    "\n",
    "### Different types of linkage\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_linkage_comparison_001.png)\n",
    "\n",
    "### How are they computed?\n",
    "![](../figures/linkage_types.jpeg)\n",
    "\n",
    "**Ward linkage**: minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.\n",
    "\n",
    "### The distance matrix\n",
    "![](../figures/hc_distance_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](../figures/hierarch.gif)\n",
    "\n",
    "(From https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics:\n",
    "- *bottom up approach*: each observation starts in its own cluster, and clusters are successively merged together\n",
    "- *greedy/local algorithm*: at each iteration tries to minimize the distance of cluster merging\n",
    "- *no realocation*: after an observation is assigned to a cluster, it can no longer change\n",
    "- *deterministic*: you always get the same answer when you run it\n",
    "- *scalability*: can become *very slow* for a large number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to apply Hierarchical Clustering?\n",
    "**Note: Which types of variables should be used for clustering?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performing HC\n",
    "hclust = AgglomerativeClustering(linkage='ward', metric='euclidean', n_clusters=5)\n",
    "hc_labels = hclust.fit_predict(df[metric_features])\n",
    "hc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the clusters\n",
    "df_concat = pd.concat((df, pd.Series(hc_labels, name='labels', index=df.index)), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the linkage method to choose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to understand that:**\n",
    "$$SS_{t} = SS_{w} + SS_{b}$$\n",
    "\n",
    "---\n",
    "\n",
    "$$SS_{t} = \\sum\\limits_{i = 1}^n {{{({x_i} - \\overline x )}^2}}$$\n",
    "\n",
    "$$SS_{w} = \\sum\\limits_{k = 1}^K {\\sum\\limits_{i = 1}^{{n_k}} {{{({x_i} - {{\\overline x }_k})}^2}} }$$\n",
    "\n",
    "$$SS_{b} = \\sum\\limits_{k = 1}^K {{n_k}{{({{\\overline x }_k} - \\overline x )}^2}}$$\n",
    "\n",
    "where \n",
    "\n",
    "$n$ is the total number of observations, \n",
    "\n",
    "$x_i$ is the vector of the $i^{th}$ observation, \n",
    "\n",
    "$\\overline x$ is the centroid of the data, \n",
    "\n",
    "$K$  is the number of clusters, \n",
    "\n",
    "$n_k$ is the number of observations in the $k^{th}$ cluster,\n",
    "\n",
    "and $\\overline x_k$ is the centroid of the $k^{th}$ cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figures/ssw_ssb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing SST\n",
    "X = df[metric_features].values\n",
    "sst = np.sum(np.square(X - X.mean(axis=0)), axis=0)\n",
    "\n",
    "# Computing SSW\n",
    "ssw_iter = []\n",
    "for i in np.unique(hc_labels):\n",
    "    X_k = X[hc_labels == i]\n",
    "    ssw_iter.append(np.sum(np.square(X_k - X_k.mean(axis=0)), axis=0))\n",
    "ssw = np.sum(ssw_iter, axis=0)\n",
    "\n",
    "# Computing SSB\n",
    "ssb_iter = []\n",
    "for i in np.unique(hc_labels):\n",
    "    X_k = X[hc_labels == i]\n",
    "    ssb_iter.append(X_k.shape[0] * np.square(X_k.mean(axis=0) - X.mean(axis=0)))\n",
    "ssb = np.sum(ssb_iter, axis=0)\n",
    "\n",
    "# Verifying the formula\n",
    "np.round(sst) == np.round((ssw + ssb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_hc(df, link_method, max_nclus, min_nclus=1, dist=\"euclidean\"):\n",
    "    \"\"\"This function computes the R2 for a set of cluster solutions given by the application of a hierarchical method.\n",
    "    The R2 is a measure of the homogenity of a cluster solution. It is based on SSt = SSw + SSb and R2 = SSb/SSt. \n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataset to apply clustering\n",
    "    link_method (str): either \"ward\", \"complete\", \"average\", \"single\"\n",
    "    max_nclus (int): maximum number of clusters to compare the methods\n",
    "    min_nclus (int): minimum number of clusters to compare the methods. Defaults to 1.\n",
    "    dist (str): distance to use to compute the clustering solution. Must be a valid distance. Defaults to \"euclidean\".\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: R2 values for the range of cluster solutions\n",
    "    \"\"\"\n",
    "    def get_ss(df):\n",
    "        ss = np.sum(df.var() * (df.count() - 1))\n",
    "        return ss  # return sum of sum of squares of each df variable\n",
    "    \n",
    "    sst = get_ss(df)  # get total sum of squares\n",
    "    \n",
    "    r2 = []  # where we will store the R2 metrics for each cluster solution\n",
    "    \n",
    "    for i in range(min_nclus, max_nclus+1):  # iterate over desired ncluster range\n",
    "        cluster = AgglomerativeClustering(n_clusters=i, metric=dist, linkage=link_method)\n",
    "        \n",
    "        \n",
    "        # get cluster labels\n",
    "        hclabels = cluster.fit_predict(df) \n",
    "        \n",
    "        \n",
    "        # concat df with labels\n",
    "        df_concat = pd.concat((df, pd.Series(hclabels, name='labels', index=df.index)), axis=1)  \n",
    "        \n",
    "        \n",
    "        # compute ssw for each cluster labels\n",
    "        ssw_labels = df_concat.groupby(by='labels').apply(get_ss)  \n",
    "        \n",
    "        \n",
    "        # remember: SST = SSW + SSB\n",
    "        ssb = sst - np.sum(ssw_labels)  \n",
    "        \n",
    "        \n",
    "        r2.append(ssb / sst)  # save the R2 of the given cluster solution\n",
    "        \n",
    "    return np.array(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "hc_methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "# Call function defined above to obtain the R2 statistic for each hc_method\n",
    "max_nclus = 10\n",
    "r2_hc_methods = np.vstack(\n",
    "    [\n",
    "        get_r2_hc(df=df[metric_features], link_method=link, max_nclus=max_nclus) \n",
    "        for link in hc_methods\n",
    "    ]\n",
    ").T\n",
    "r2_hc_methods = pd.DataFrame(r2_hc_methods, index=range(1, max_nclus + 1), columns=hc_methods)\n",
    "\n",
    "sns.set()\n",
    "# Plot data\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "sns.lineplot(data=r2_hc_methods, linewidth=2.5, markers=[\"o\"]*4)\n",
    "\n",
    "# Finalize the plot\n",
    "fig.suptitle(\"R2 plot for various hierarchical methods\", fontsize=21)\n",
    "plt.gca().invert_xaxis()  # invert x axis\n",
    "plt.legend(title=\"HC methods\", title_fontsize=11)\n",
    "plt.xticks(range(1, max_nclus + 1))\n",
    "plt.xlabel(\"Number of clusters\", fontsize=13)\n",
    "plt.ylabel(\"R2 metric\", fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the number of clusters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the **first big jump** on the Dendrogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting distance_threshold=0 and n_clusters=None ensures we compute the full tree\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, distance_threshold=0, n_clusters=None)\n",
    "hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py\n",
    "\n",
    "# create the counts of samples under each node (number of points being merged)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 100\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering - {linkage.title()}\\'s Dendrogram', fontsize=21)\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cluster solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 cluster solution\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hc4lust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=4)\n",
    "hc4_labels = hc4lust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the 4 clusters\n",
    "df_concat = pd.concat((df, pd.Series(hc4_labels, name='labels', index=df.index)), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 cluster solution\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hc5lust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=5)\n",
    "hc5_labels = hc5lust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the 5 clusters\n",
    "df_concat = pd.concat((df, pd.Series(hc5_labels, name='labels', index=df.index)), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's put both HC4 and HC5 labels in the same df to compare\n",
    "\n",
    "df_hc4_hc5 = pd.concat((df,\n",
    "                        pd.Series(hc4_labels,\n",
    "                                  name='hc4_labels',\n",
    "                                  index=df.index),\n",
    "                        pd.Series(hc5_labels,\n",
    "                                  name='hc5_labels',\n",
    "                                  index=df.index)\n",
    "                        ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See crosstab of 4 vs 5\n",
    "\n",
    "pd.crosstab(df_hc4_hc5['hc5_labels'],\n",
    "           df_hc4_hc5['hc4_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hierarchical clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cluster solution\n",
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, n_clusters=4)\n",
    "hc_labels = hclust.fit_predict(df[metric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterizing the final clusters\n",
    "df_concat = pd.concat((df, pd.Series(hc_labels, name='labels', index=df.index)), axis=1)\n",
    "df_concat.groupby('labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_means = df_concat.groupby('labels').mean()[metric_features].T\n",
    "cluster_means.style.format(precision=2).background_gradient(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
